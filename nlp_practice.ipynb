{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-practice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKWykbiwdFaS2N8KMSiYBX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meghraj-Webllisto/code/blob/main/nlp_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3aMm5B-RT-M",
        "outputId": "1027c56f-71b5-4077-bd8b-e81daf7364e7"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-8aa701fd-78e1-f41b-1b6d-64e9a1b1a228)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZfE4LmhSnsi",
        "outputId": "d22c6b8a-49ae-4375-b96c-134d1e7e4d2b"
      },
      "source": [
        "# Let Download some helper function\n",
        "! wget http://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-24 10:58:08--  http://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py [following]\n",
            "--2021-05-24 10:58:08--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-24 10:58:08 (112 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN-JpqjmTz-f"
      },
      "source": [
        "# Import Series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlgLnk2vUEou",
        "outputId": "e720d57d-dbe4-4209-c017-af81ba3e8ff7"
      },
      "source": [
        "# Download the dataset\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-24 10:58:10--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.62.128, 172.217.164.176, 172.253.115.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.62.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-05-24 10:58:10 (109 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Hn6xd9sVWnxm",
        "outputId": "a5f52cb6-0055-4596-abc5-ee5d39d86c1e"
      },
      "source": [
        "# reading csv using pandas\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "GDNHyDYIW745",
        "outputId": "5cd5aebc-e1a2-4524-fde6-2bd031c30f13"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuflle with random state=42 for reproducebility\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "GoA4xgzrXUCT",
        "outputId": "ff337405-4e05-45ba-f598-0017aabb8cd2"
      },
      "source": [
        "test_df.head()\n",
        "# test doesn't have target column"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9VRIEAFXdky",
        "outputId": "bd1b5b7d-7f78-4a60-8b1a-f9e41ab49ea9"
      },
      "source": [
        "# how many examples of each class\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkD1GPHCX5dY"
      },
      "source": [
        "1 = real disaster tweet\n",
        "0 = not a real disaster tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_4gnCrrXs8y",
        "outputId": "30273f0c-fab3-4359-a619-65428bc8ff12"
      },
      "source": [
        "# How many smapels total?\n",
        "print(f\"Total training smapels: {len(train_df)}\" )\n",
        "print(f\"total test smaples: {len(test_df)}\")\n",
        "print(f\"Total Samples: {len(train_df) + len(test_df)}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training smapels: 7613\n",
            "total test smaples: 3263\n",
            "Total Samples: 10876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBIwvn9TYbsA",
        "outputId": "3118ad1b-2d25-4b81-8377-c2a27e74b129"
      },
      "source": [
        "# Let visualizer some training example\n",
        "import random \n",
        "random_index = random.randint(0, len(train_df)-5)  # Creaete radom index not highter than total number of samples\n",
        "for row in train_df_shuffled[[\"text\",\"target\"]][random_index:random_index+5].itertuples():\n",
        "    _, text, target = row\n",
        "    print(f\"Target: {target}\", \"(real disaster)\" if target >0 else \"(not real disaster)\")\n",
        "    print(f\"Text: \\n{text}\\n\")\n",
        "    print(f\"---\\n\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 1 (real disaster)\n",
            "Text: \n",
            "Malaysian Officials Say Debris Found on Reunion Island Is From #MH370. @BillNeelyNBC reports: http://t.co/r6kZSQDghZ\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text: \n",
            "@rachelcaine The weatherit needs to make it minds up. First snow tornadoes now would you say a heat wave?\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text: \n",
            "Upheaval high note for bush opera http://t.co/aWPU0gaE0b #Sydney #News #Aus\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text: \n",
            "RT @NLM_DIMRC: A deluge of resources on #floods for medical providers cleanup workers &amp; more at: http://t.co/aUoeyIRqE6\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text: \n",
            "Thinking about getting a demo car with a friend and joining the demolition derby in kenosha\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMFBp3JkZ3ro"
      },
      "source": [
        "# split data into trian and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIU-8gfbZpiC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # 10% percent only for validations\n",
        "                                                                            random_state=42) # for reproducebility"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWnxyjFNaiT2",
        "outputId": "9a3b9b9c-84a8-435b-cca1-699257539750"
      },
      "source": [
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DPgPbHFa1qG",
        "outputId": "81421c90-ff9c-41c1-99eb-1c0722a947e5"
      },
      "source": [
        "# view some sampels \n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy4vIdWeeX74"
      },
      "source": [
        "# Converting text into number because it need numbers to run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95OC6lS4bC6W"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization\n",
        "text_vectorizer = TextVectorization(max_tokens=None,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=None,\n",
        "                                    pad_to_max_tokens=True)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2BsrOuRkwy7",
        "outputId": "162f6313-1c32-4424-c1aa-f97e085b4a89"
      },
      "source": [
        "# find the average number of tokens(words) in training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FWAuJNNlDtU"
      },
      "source": [
        "# setup text vectorization variables\n",
        "max_vocab_length = 10000\n",
        "max_length =15\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_uBpz-Kley3"
      },
      "source": [
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2NEbSlZmKgr",
        "outputId": "7ea81af7-fba7-42f2-8a66-6eb4273301d6"
      },
      "source": [
        "# Creating a sample sentence \n",
        "smaple_sentence = \" There's  a flood in my area.\"\n",
        "text_vectorizer([smaple_sentence])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 408,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrLyyKHZmdrN",
        "outputId": "d73a72cc-f10c-4c92-df22-71ddd027572f"
      },
      "source": [
        "# unqiue workds in vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tolens ([unk] for unknown words)\n",
        "bottom_5_words = words_in_vocab[-5:]\n",
        "print(f\"Numbner of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 Most common words: {top_5_words}\")\n",
        "print(f\"Bottom 5 Most common words: {bottom_5_words}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numbner of words in vocab: 10000\n",
            "Top 5 Most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 Most common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw2Wk8LCnoXr"
      },
      "source": [
        "# Creating an Embeding using Embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WQyU1qCmxK1",
        "outputId": "43295e95-e1af-4e3b-a308-0c370cea72ef"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer='uniform',\n",
        "                             input_length=max_length)\n",
        "embedding"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f6f410895d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz6rJcTPo5Ym",
        "outputId": "7d5163b3-4df4-4ae5-852b-2e58b28fff97"
      },
      "source": [
        "# lets check one sentence in embedding\n",
        "random_sentences =  random.choice(train_sentences)\n",
        "\n",
        "print(f\"original sentence: {random_sentences}\")\n",
        "sample_embedding_output = embedding(text_vectorizer([random_sentences]))\n",
        "sample_embedding_output"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original sentence: I liked a @YouTube video from @sqwizzix http://t.co/GGqCz9AB6u Call of Duty: ÛÏThe Piano EntertainerÛ Ep. 9 ÛÒ Musicians Collide!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.03174826,  0.01158581,  0.00996625, ..., -0.02533834,\n",
              "         -0.03915069,  0.04471805],\n",
              "        [-0.03315306,  0.02884961, -0.04337993, ..., -0.00401814,\n",
              "          0.03109732,  0.03304734],\n",
              "        [ 0.00385405,  0.00966021,  0.02291754, ...,  0.02427837,\n",
              "          0.0163605 ,  0.0423292 ],\n",
              "        ...,\n",
              "        [ 0.02526024, -0.03154299,  0.04741411, ..., -0.01185925,\n",
              "          0.04993299, -0.00743997],\n",
              "        [-0.03934727,  0.02316416, -0.03660525, ..., -0.01022897,\n",
              "         -0.02393894, -0.04484742],\n",
              "        [ 0.0151295 ,  0.03419603,  0.02264159, ..., -0.03119685,\n",
              "          0.04130092,  0.04536611]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JNF7HTDqo0s",
        "outputId": "84a6e273-31f5-4e90-fe47-c0474b05fc1f"
      },
      "source": [
        "type(sample_embedding_output)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3KmrWgqq7p_",
        "outputId": "566fa74d-5301-484f-bff2-bac94d65f291"
      },
      "source": [
        "sample_embedding_output[0][-2]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([-0.03934727,  0.02316416, -0.03660525, -0.01670171,  0.00292802,\n",
              "        0.03768024,  0.0345413 ,  0.0417153 , -0.00675485, -0.04380372,\n",
              "       -0.01049144,  0.02630904, -0.01389908, -0.02584611, -0.04274907,\n",
              "       -0.04907848, -0.01506655,  0.01589736, -0.01081372,  0.01571088,\n",
              "        0.03448464, -0.0324118 , -0.00297669,  0.02135867, -0.03960029,\n",
              "       -0.01683478, -0.0081922 , -0.01378689, -0.04670122,  0.03760168,\n",
              "        0.02323138, -0.03776643,  0.01622428,  0.03877488,  0.04728338,\n",
              "       -0.03817146,  0.03731562, -0.04270599, -0.01726912,  0.01677345,\n",
              "       -0.04429947,  0.04612657, -0.00360105,  0.04525885, -0.04241545,\n",
              "       -0.02366905, -0.0409417 ,  0.02648741,  0.03140214,  0.02927352,\n",
              "        0.02682981,  0.02163167,  0.00640206, -0.00723679,  0.04304523,\n",
              "        0.03044847, -0.00305087, -0.01877788, -0.00396074,  0.03108729,\n",
              "       -0.04338261, -0.02178837, -0.04950574,  0.0234058 ,  0.00891101,\n",
              "       -0.04479663,  0.03944312, -0.03531975,  0.02517681,  0.03958759,\n",
              "       -0.03937347, -0.04800444, -0.01479543,  0.01456786,  0.02875432,\n",
              "        0.02841021,  0.0063926 , -0.02434046, -0.04128034, -0.03406236,\n",
              "       -0.03959854,  0.0459356 , -0.00896158,  0.03972304,  0.03180828,\n",
              "       -0.02719759, -0.02751174,  0.01136395, -0.02238568,  0.00015843,\n",
              "       -0.01817841,  0.03858164,  0.03941742, -0.01865887,  0.01270321,\n",
              "       -0.03071202, -0.01419196,  0.00936817,  0.03727779,  0.03548703,\n",
              "       -0.03864412,  0.00811471,  0.0148296 , -0.01725603, -0.01969813,\n",
              "       -0.01942123,  0.03615384,  0.01166346, -0.02089145, -0.01352284,\n",
              "       -0.0218302 ,  0.02858177,  0.00566636,  0.04378343, -0.01812018,\n",
              "       -0.00109867, -0.02097136, -0.02687003, -0.00025592,  0.04361336,\n",
              "        0.04065515,  0.03205513,  0.01667101, -0.0179103 ,  0.00820744,\n",
              "       -0.01022897, -0.02393894, -0.04484742], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u13OremKrJpO"
      },
      "source": [
        "Embedding is ready , let build model if we can , there is no we just me MRJ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KplHJp0Wtu3g"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5fgUR9OuYbk"
      },
      "source": [
        "# THE NAIVE BASE model(baseline)\n",
        "![](https://cdn.journaldev.com/wp-content/uploads/2020/10/NAIVE-BAYES-1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmoMOaDuu5Rw",
        "outputId": "9fcc235e-78f0-491d-e3a1-6f892f734f54"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Creating tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()),\n",
        "                    (\"clf\", MultinomialNB()),\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMBC1GP7yJZR"
      },
      "source": [
        "The benifit of shallow model like MultinomialNB is that trianing is very fast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iap9wUESyF6o",
        "outputId": "9e63ac24-89e0-4831-88ae-b1753acb0f69"
      },
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"baseline model has an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "baseline model has an accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk9F3X2EyxP2",
        "outputId": "a3bdd3a0-2f3e-4111-b127-d9ebff6bbbc8"
      },
      "source": [
        "# makeing prediction\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7Rdl58RCViy"
      },
      "source": [
        "# Creating an evaluation function for our model experiments\n",
        "it will evaluate\n",
        "accuracy \n",
        "\n",
        "precision\n",
        "\n",
        "Recall\n",
        "\n",
        "F1-score\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stupionuy8TW"
      },
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "    Args :\n",
        "    y_true : True labels in the form of a 1 d array\n",
        "    y_pred : predicted labels in the form of a 1d array\n",
        "    Return a dictionary of accuracy, precision, recall, f1-score.\n",
        "    \"\"\"\n",
        "    # calcualte model accuracy\n",
        "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "    # calculate model precision, recall and f1 score using \"weighted\" average\n",
        "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred,  average=\"weighted\")\n",
        "    model_results = {\"accuracy\" : model_accuracy,\n",
        "                     \"precision\" : model_precision,\n",
        "                     \"recall\": model_recall,\n",
        "                     \"f1\": model_f1}\n",
        "    return model_results"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esEErHJEEaLZ",
        "outputId": "5b860103-201a-4da9-cb6c-7db8e5d32edd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels, y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krXoFlMVEytD"
      },
      "source": [
        "# model 1:A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp3P9kGTEoHC"
      },
      "source": [
        "from helper_functions import create_tensorboard_callback\n",
        "SAVE_DIR = \"model_logs\" # tensorboard log dirs"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wniAFMduFCjs"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # input are 1 dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # Create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding \n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # consturct the model."
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z9d1svDGY8H"
      },
      "source": [
        "# compile the model \n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=['acc'])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VngtVLCLG3aY",
        "outputId": "54782dc6-9d55-4df4-a6d2-75b765241d42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhEnyWlNG_GU",
        "outputId": "570e16c7-e543-4e3a-bed8-86a0cdc1bbf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# fit a model\n",
        "model_1_history = model_1.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20210524-112435\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 16ms/step - loss: 0.6526 - acc: 0.6390 - val_loss: 0.5354 - val_acc: 0.7559\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.4611 - acc: 0.8151 - val_loss: 0.4711 - val_acc: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.3537 - acc: 0.8607 - val_loss: 0.4588 - val_acc: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.2806 - acc: 0.8942 - val_loss: 0.4653 - val_acc: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.2314 - acc: 0.9207 - val_loss: 0.4856 - val_acc: 0.7913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saliSYr1Hl58"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}